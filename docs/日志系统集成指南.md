# Carrot YARN 日志系统集成指南

## 概述

Carrot YARN 已升级为功能丰富的分层日志系统，支持：

- **按小时轮转的文件日志**
- **每日零点自动压缩**
- **Kafka 实时日志流**
- **Doris 数据仓库存储**
- **可配置的多输出管道**

## 功能特性

### 1. 文件日志系统

- ✅ **按小时轮转**: 每小时创建新的日志文件 (`carrot-2025-08-26-14.log`)
- ✅ **每日压缩**: 零点自动压缩前一天的所有小时日志文件
- ✅ **智能清理**: 根据配置保留指定天数的日志文件
- ✅ **大小限制**: 单个文件大小可配置，防止文件过大

### 2. Kafka 集成

- ✅ **异步发送**: 高性能批量发送到 Kafka
- ✅ **可靠传输**: 支持重试和错误处理
- ✅ **分组日志**: 不同组件可发送到不同 Topic

### 3. Doris 集成

- ✅ **批量插入**: 通过 Stream Load API 高效插入
- ✅ **定时刷新**: 可配置的缓冲区刷新间隔
- ✅ **结构化存储**: JSON 格式的结构化日志存储

## 配置说明

### 日志配置结构

```yaml
log:
  level: "info"                    # 日志级别: debug, info, warn, error
  development: false               # 开发模式
  
  # 文件输出配置
  file_output:
    enabled: true                  # 启用文件输出
    directory: "logs/componentname" # 日志目录
    max_file_size: "100MB"         # 单文件最大大小
    max_backups: 168               # 保留文件数量(168=7天*24小时)
    max_age: 7                     # 保留天数
    compress: true                 # 压缩旧文件
    hourly_rotation: true          # 按小时轮转
    daily_compression: true        # 每日压缩
  
  # Kafka 输出配置
  kafka_output:
    enabled: false                 # 启用 Kafka 输出
    brokers: ["localhost:9092"]    # Kafka 集群地址
    topic: "carrot-logs"           # 主题名称
    batch_size: 100                # 批量大小
    timeout: "10s"                 # 发送超时
    retries: 3                     # 重试次数
  
  # Doris 输出配置
  doris_output:
    enabled: false                 # 启用 Doris 输出
    stream_load_url: "http://localhost:8030/api/carrot_logs/logs/_stream_load"
    database: "carrot_logs"        # 数据库名
    table: "logs"                  # 表名
    username: "root"               # 用户名
    password: ""                   # 密码
    batch_size: 1000               # 批量大小
    flush_interval: "30s"          # 刷新间隔
  
  # 控制台输出配置
  console_output:
    enabled: true                  # 启用控制台输出
    colorized: false               # 彩色输出
```

### 组件配置示例

#### ResourceManager 日志配置

```yaml
log:
  level: "info"
  file_output:
    enabled: true
    directory: "logs/resourcemanager"
  kafka_output:
    enabled: true
    topic: "carrot-rm-logs"
  doris_output:
    enabled: true
    stream_load_url: "http://localhost:8030/api/carrot_logs/rm_logs/_stream_load"
    table: "rm_logs"
```

#### NodeManager 日志配置

```yaml
log:
  level: "info"
  file_output:
    enabled: true
    directory: "logs/nodemanager"
  kafka_output:
    enabled: true
    topic: "carrot-nm-logs"
  doris_output:
    enabled: true
    table: "nm_logs"
```

#### ApplicationMaster 日志配置

```yaml
log:
  level: "debug"
  file_output:
    enabled: true
    directory: "logs/applicationmaster"
  kafka_output:
    enabled: true
    topic: "carrot-am-logs"
  doris_output:
    enabled: true
    table: "am_logs"
```

## Doris 表结构

### 创建数据库

```sql
CREATE DATABASE IF NOT EXISTS carrot_logs;
USE carrot_logs;
```

### ResourceManager 日志表

```sql
CREATE TABLE IF NOT EXISTS rm_logs (
    `timestamp` DATETIME,
    `level` VARCHAR(10),
    `component` VARCHAR(50),
    `message` TEXT,
    `fields` JSON
) ENGINE=OLAP
DUPLICATE KEY(`timestamp`, `level`, `component`)
PARTITION BY RANGE(`timestamp`)
(
    PARTITION p20250826 VALUES [('2025-08-26 00:00:00'), ('2025-08-27 00:00:00')),
    PARTITION p20250827 VALUES [('2025-08-27 00:00:00'), ('2025-08-28 00:00:00'))
)
DISTRIBUTED BY HASH(`timestamp`) BUCKETS 8
PROPERTIES (
    "replication_allocation" = "tag.location.default: 1",
    "dynamic_partition.enable" = "true",
    "dynamic_partition.time_unit" = "DAY",
    "dynamic_partition.create_history_partition" = "true",
    "dynamic_partition.history_partition_num" = "30",
    "dynamic_partition.hot_partition_num" = "7"
);
```

### NodeManager 日志表

```sql
CREATE TABLE IF NOT EXISTS nm_logs (
    `timestamp` DATETIME,
    `level` VARCHAR(10),
    `component` VARCHAR(50),
    `message` TEXT,
    `fields` JSON
) ENGINE=OLAP
DUPLICATE KEY(`timestamp`, `level`, `component`)
PARTITION BY RANGE(`timestamp`)
(
    PARTITION p20250826 VALUES [('2025-08-26 00:00:00'), ('2025-08-27 00:00:00')),
    PARTITION p20250827 VALUES [('2025-08-27 00:00:00'), ('2025-08-28 00:00:00'))
)
DISTRIBUTED BY HASH(`timestamp`) BUCKETS 8
PROPERTIES (
    "replication_allocation" = "tag.location.default: 1",
    "dynamic_partition.enable" = "true",
    "dynamic_partition.time_unit" = "DAY",
    "dynamic_partition.create_history_partition" = "true",
    "dynamic_partition.history_partition_num" = "30",
    "dynamic_partition.hot_partition_num" = "7"
);
```

### ApplicationMaster 日志表

```sql
CREATE TABLE IF NOT EXISTS am_logs (
    `timestamp` DATETIME,
    `level` VARCHAR(10),
    `component` VARCHAR(50),
    `message` TEXT,
    `fields` JSON
) ENGINE=OLAP
DUPLICATE KEY(`timestamp`, `level`, `component`)
PARTITION BY RANGE(`timestamp`)
(
    PARTITION p20250826 VALUES [('2025-08-26 00:00:00'), ('2025-08-27 00:00:00')),
    PARTITION p20250827 VALUES [('2025-08-27 00:00:00'), ('2025-08-28 00:00:00'))
)
DISTRIBUTED BY HASH(`timestamp`) BUCKETS 8
PROPERTIES (
    "replication_allocation" = "tag.location.default: 1",
    "dynamic_partition.enable" = "true",
    "dynamic_partition.time_unit" = "DAY",
    "dynamic_partition.create_history_partition" = "true",
    "dynamic_partition.history_partition_num" = "30",
    "dynamic_partition.hot_partition_num" = "7"
);
```

## Kafka Topic 配置

### 创建日志 Topics

```bash
# ResourceManager 日志
kafka-topics.sh --create --topic carrot-rm-logs --bootstrap-rmserver localhost:9092 --partitions 3 --replication-factor 1

# NodeManager 日志  
kafka-topics.sh --create --topic carrot-nm-logs --bootstrap-rmserver localhost:9092 --partitions 3 --replication-factor 1

# ApplicationMaster 日志
kafka-topics.sh --create --topic carrot-am-logs --bootstrap-rmserver localhost:9092 --partitions 3 --replication-factor 1
```

### 消费日志示例

```bash
# 消费 ResourceManager 日志
kafka-console-consumer.sh --topic carrot-rm-logs --bootstrap-rmserver localhost:9092 --from-beginning

# 消费 NodeManager 日志
kafka-console-consumer.sh --topic carrot-nm-logs --bootstrap-rmserver localhost:9092 --from-beginning

# 消费 ApplicationMaster 日志
kafka-console-consumer.sh --topic carrot-am-logs --bootstrap-rmserver localhost:9092 --from-beginning
```

## 使用示例

### 1. 启用完整日志系统

修改配置文件启用所有输出：

```yaml
# resourcemanager.yaml
log:
  level: "info"
  file_output:
    enabled: true
  kafka_output:
    enabled: true
    brokers: [ "kafka1:9092", "kafka2:9092", "kafka3:9092" ]
  doris_output:
    enabled: true
    stream_load_url: "http://doris-fe:8030/api/carrot_logs/rm_logs/_stream_load"
    username: "carrot_user"
    password: "carrot_password"
  console_output:
    enabled: true
```

### 2. 仅文件日志（生产环境推荐）

```yaml
log:
  level: "warn"
  file_output:
    enabled: true
    directory: "/var/log/carrot/resourcemanager"
    max_file_size: "500MB"
    max_backups: 336  # 14天 * 24小时
    max_age: 14
  kafka_output:
    enabled: false
  doris_output:
    enabled: false
  console_output:
    enabled: false
```

### 3. 开发调试模式

```yaml
log:
  level: "debug"
  development: true
  file_output:
    enabled: true
    directory: "logs/debug"
  kafka_output:
    enabled: false
  doris_output:
    enabled: false
  console_output:
    enabled: true
    colorized: true
```

## 日志文件结构

### 文件命名规则

```
logs/
├── resourcemanager/
│   ├── carrot-2025-08-26-09.log      # 9点的日志
│   ├── carrot-2025-08-26-10.log      # 10点的日志
│   ├── carrot-2025-08-26-11.log      # 11点的日志
│   ├── carrot-2025-08-25-23.log.gz   # 前一天压缩后的日志
│   └── carrot-2025-08-25-22.log.gz
├── nodemanager/
│   ├── carrot-2025-08-26-09.log
│   └── carrot-2025-08-26-10.log
└── applicationmaster/
    ├── carrot-2025-08-26-09.log
    └── carrot-2025-08-26-10.log
```

### 日志格式示例

#### JSON 格式（文件/Kafka/Doris）

```json
{
  "timestamp": "2025-08-26T14:30:15.123Z",
  "level": "INFO",
  "component": "resourcemanager",
  "message": "Node heartbeat received",
  "fields": {
    "node_id": "nm-001",
    "memory_used": 4096,
    "vcores_used": 4,
    "containers": 3
  }
}
```

#### 控制台格式（开发模式）

```
2025-08-26T14:30:15.123+08:00  INFO  resourcemanager  Node heartbeat received  {"node_id": "nm-001", "memory_used": 4096}
```

## 监控和运维

### 1. 日志文件监控

```bash
# 检查日志文件大小
du -sh logs/*/

# 检查今天的日志文件
ls -la logs/*/carrot-$(date +%Y-%m-%d)-*.log

# 检查压缩的日志文件
ls -la logs/*/carrot-*.log.gz
```

### 2. Kafka 监控

```bash
# 检查 Topic 消息数量
kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list localhost:9092 --topic carrot-rm-logs

# 查看消费者状态
kafka-consumer-groups.sh --bootstrap-rmserver localhost:9092 --group carrot-log-group --describe
```

### 3. Doris 监控

```sql
-- 查看日志表大小
SELECT 
    table_name,
    count(*) as row_count,
    sum(data_size) as total_size
FROM information_schema.partitions 
WHERE table_schema = 'carrot_logs'
GROUP BY table_name;

-- 查看今天的日志条数
SELECT component, level, count(*) 
FROM carrot_logs.rm_logs 
WHERE timestamp >= CURDATE() 
GROUP BY component, level;
```

## 故障排除

### 1. 文件权限问题

```bash
# 确保日志目录有写权限
chmod -R 755 logs/
chown -R carrot:carrot logs/
```

### 2. Kafka 连接问题

- 检查 Kafka 集群是否可达
- 验证 Topic 是否存在
- 检查网络防火墙设置

### 3. Doris 连接问题

- 验证 Stream Load URL 是否正确
- 检查用户名密码
- 确认表结构与日志格式匹配

### 4. 磁盘空间监控

```bash
# 监控日志目录磁盘使用
df -h logs/

# 清理过期日志（如果自动清理失败）
find logs/ -name "*.log.gz" -mtime +30 -delete
```

## 性能优化建议

1. **文件日志优化**
    - 使用 SSD 存储提高写入性能
    - 适当调整 `max_file_size` 避免频繁轮转
    - 定期清理过期日志文件

2. **Kafka 优化**
    - 调整 `batch_size` 和 `timeout` 平衡性能与实时性
    - 使用多个 partition 提高并发性能
    - 配置适当的 retention 策略

3. **Doris 优化**
    - 调整 `batch_size` 和 `flush_interval` 优化写入性能
    - 使用合适的分区策略
    - 定期优化表结构和索引

这个日志系统为 Carrot YARN 提供了企业级的日志管理能力，支持从开发调试到生产运维的全场景需求。
